{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path ke folder dataset\n",
    "data_folder = \"DS-6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ekstrak data dan label dari folder\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            filepath = os.path.join(folder, filename)\n",
    "            image = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)  # Baca sebagai grayscale\n",
    "            if image is not None:\n",
    "                image = cv2.resize(image, (28, 28))  # Resize ke 28x28\n",
    "                images.append(image)\n",
    "                label = filename.split('_')[0]\n",
    "                labels.append(int(label) if label.isdigit() else 0)  # Default ke 0 jika label tidak valid\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images...\n",
      "Loaded 8549 images.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "print(\"Loading images...\")\n",
    "images, labels = load_images_from_folder(data_folder)\n",
    "if len(images) == 0:\n",
    "    print(\"No valid images found in the folder. Exiting...\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Loaded {len(labels)} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisasi data\n",
    "images = images / 255.0  # Normalisasi nilai piksel ke [0, 1]\n",
    "images = images.reshape(-1, 28, 28, 1)  # Tambahkan channel untuk CNN\n",
    "labels = to_categorical(labels, num_classes=10)  # One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data untuk latih dan uji\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentasi data\n",
    "datagen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1)\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membangun model CNN\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kompilasi model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/20\n",
      "161/161 - 4s - 22ms/step - accuracy: 0.1306 - loss: 2.2899 - val_accuracy: 0.1749 - val_loss: 2.1918\n",
      "Epoch 2/20\n",
      "161/161 - 2s - 13ms/step - accuracy: 0.3391 - loss: 1.8879 - val_accuracy: 0.7117 - val_loss: 1.0417\n",
      "Epoch 3/20\n",
      "161/161 - 2s - 12ms/step - accuracy: 0.5514 - loss: 1.3403 - val_accuracy: 0.8333 - val_loss: 0.6698\n",
      "Epoch 4/20\n",
      "161/161 - 2s - 11ms/step - accuracy: 0.6489 - loss: 1.0753 - val_accuracy: 0.8836 - val_loss: 0.4494\n",
      "Epoch 5/20\n",
      "161/161 - 2s - 11ms/step - accuracy: 0.6992 - loss: 0.9155 - val_accuracy: 0.8749 - val_loss: 0.4109\n",
      "Epoch 6/20\n",
      "161/161 - 2s - 12ms/step - accuracy: 0.7491 - loss: 0.8075 - val_accuracy: 0.9184 - val_loss: 0.2923\n",
      "Epoch 7/20\n",
      "161/161 - 2s - 12ms/step - accuracy: 0.7744 - loss: 0.7131 - val_accuracy: 0.9287 - val_loss: 0.2509\n",
      "Epoch 8/20\n",
      "161/161 - 2s - 11ms/step - accuracy: 0.7910 - loss: 0.6598 - val_accuracy: 0.9298 - val_loss: 0.2418\n",
      "Epoch 9/20\n",
      "161/161 - 2s - 11ms/step - accuracy: 0.8138 - loss: 0.5914 - val_accuracy: 0.9374 - val_loss: 0.2062\n",
      "Epoch 10/20\n",
      "161/161 - 2s - 12ms/step - accuracy: 0.8275 - loss: 0.5447 - val_accuracy: 0.9456 - val_loss: 0.1947\n",
      "Epoch 11/20\n",
      "161/161 - 2s - 12ms/step - accuracy: 0.8386 - loss: 0.5218 - val_accuracy: 0.9477 - val_loss: 0.1778\n",
      "Epoch 12/20\n",
      "161/161 - 2s - 12ms/step - accuracy: 0.8464 - loss: 0.5073 - val_accuracy: 0.9553 - val_loss: 0.1630\n",
      "Epoch 13/20\n",
      "161/161 - 2s - 12ms/step - accuracy: 0.8645 - loss: 0.4516 - val_accuracy: 0.9594 - val_loss: 0.1404\n",
      "Epoch 14/20\n",
      "161/161 - 2s - 14ms/step - accuracy: 0.8682 - loss: 0.4302 - val_accuracy: 0.9623 - val_loss: 0.1318\n",
      "Epoch 15/20\n",
      "161/161 - 2s - 12ms/step - accuracy: 0.8694 - loss: 0.4282 - val_accuracy: 0.9678 - val_loss: 0.1251\n",
      "Epoch 16/20\n",
      "161/161 - 2s - 12ms/step - accuracy: 0.8787 - loss: 0.3914 - val_accuracy: 0.9684 - val_loss: 0.1211\n",
      "Epoch 17/20\n",
      "161/161 - 2s - 12ms/step - accuracy: 0.8783 - loss: 0.3943 - val_accuracy: 0.9699 - val_loss: 0.1167\n",
      "Epoch 18/20\n",
      "161/161 - 2s - 12ms/step - accuracy: 0.8865 - loss: 0.3608 - val_accuracy: 0.9728 - val_loss: 0.1135\n",
      "Epoch 19/20\n",
      "161/161 - 2s - 12ms/step - accuracy: 0.8887 - loss: 0.3524 - val_accuracy: 0.9722 - val_loss: 0.1110\n",
      "Epoch 20/20\n",
      "161/161 - 2s - 11ms/step - accuracy: 0.8994 - loss: 0.3262 - val_accuracy: 0.9769 - val_loss: 0.1037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Pelatihan model\n",
    "print(\"Training the model...\")\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=20, verbose=2)\n",
    "\n",
    "model.save('model/cnn_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model...\n",
      "107/107 - 0s - 2ms/step - accuracy: 0.9769 - loss: 0.1037\n",
      "Test accuracy: 97.69%\n"
     ]
    }
   ],
   "source": [
    "# Evaluasi model\n",
    "print(\"Evaluating the model...\")\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Prediksi\n",
    "print(\"Making predictions...\")\n",
    "predictions = model.predict(X_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "true_labels = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True labels vs Predicted labels:\n",
      "True: 3, Predicted: 3\n",
      "True: 9, Predicted: 9\n",
      "True: 5, Predicted: 5\n",
      "True: 2, Predicted: 2\n",
      "True: 8, Predicted: 8\n",
      "True: 5, Predicted: 5\n",
      "True: 4, Predicted: 4\n",
      "True: 9, Predicted: 9\n",
      "True: 6, Predicted: 6\n",
      "True: 5, Predicted: 5\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan beberapa hasil\n",
    "print(\"True labels vs Predicted labels:\")\n",
    "for i in range(10):\n",
    "    print(f\"True: {true_labels[i]}, Predicted: {predicted_labels[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
